# Creates a Deployment and Service for a web application listening on .Values.web-worker.port.
#
# Example values.yaml:
# image: docker.io/stormix/stream-crush:latest
# deployments:
#   webWorker:
#     replicas: 1
#     memory: 512Mi
#     cpu: 250m
#     # Put ENV which should only apply to the web deployment here
#     env:
#       - name: WEB_CONCURRENCY
#         value: "2"
#     # readinessProbePath: /up # when this path returns 200 the pod will be considered ready
#     # port: <custom-port> (if you don't want to use port 80)
#     # command: <custom-command> (if you don't want to run bin/rails server)
# envFrom:
#   - secretRef:
#       name: stream-crush # Create a dedicated application secret with k secrets:create stream-crush
# env: [] # Put ENV which applies to all deployments here

{{- $port := .Values.deployments.webWorker.port | default 80 }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Chart.Name }}-web-worker
  annotations:
    reloader.stakater.com/auto: "true"
spec:
  replicas: {{ .Values.deployments.webWorker.replicas }}
  selector:
    matchLabels:
      app: {{ .Chart.Name }}-web-worker
  template:
    metadata:
      labels:
        app: {{ .Chart.Name }}-web-worker
      annotations:
        linkerd.io/inject: enabled
        kubectl.kubernetes.io/default-container: web
    spec:
      containers:
        - name: web
          image: {{ .Values.image }}
          command:
            {{- range .Values.deployments.webWorker.command | default "bundle exec rails server" | split " " }}
            - {{ . | quote }}
            {{- end }}
          ports:
            - containerPort: {{ $port }}
          securityContext:
            capabilities:
              add:
              - NET_BIND_SERVICE
          {{- if .Values.deployments.webWorker.readinessProbePath }}
          readinessProbe:
            httpGet:
              path: {{ .Values.deployments.webWorker.readinessProbePath }}
              port: {{ $port }}
          {{- end }}
          # NOTE: We avoid putting a limit on CPU since Kubernetes throttling kills performance and CPU averages
          # tends to be low, so we can allow some pods to burst when needed. Adjust as you see fit.
          resources:
            requests:
              memory: {{ .Values.deployments.webWorker.memory }}
              cpu: {{ .Values.deployments.webWorker.cpu }}
            limits:
              memory: {{ .Values.deployments.webWorker.memory }}
          envFrom: {{ .Values.envFrom | toYaml | nindent 12 }}
          env:
            {{- if .Values.env }}
            {{- .Values.env | toYaml | nindent 12 }}
            {{- end }}
            {{- if .Values.deployments.webWorker.env }}
            {{- .Values.deployments.webWorker.env | toYaml | nindent 12 }}
            {{- end }}
            - name: PORT
              value: "{{ $port }}"
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Chart.Name }}-web-worker
spec:
  type: ClusterIP
  ports:
    - port: {{ $port }}
      targetPort: {{ $port }}
      protocol: TCP
  selector:
    app: {{ .Chart.Name }}-web-worker
